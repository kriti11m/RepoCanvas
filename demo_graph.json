{
  "nodes": [
    {
      "id": "function:read_file:worker/parse_repo.py:8",
      "name": "read_file",
      "file": "worker/parse_repo.py",
      "start_line": 8,
      "end_line": 11,
      "code": "def read_file(file_path):\n    \"\"\"Read file contents as string.\"\"\"\n    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n        return f.read()",
      "doc": "Read file contents as string.",
      "num_calls_out": 0,
      "num_calls_in": 1,
      "loc": 4,
      "cyclomatic": 2
    },
    {
      "id": "function:get_file_extension:worker/parse_repo.py:13",
      "name": "get_file_extension",
      "file": "worker/parse_repo.py",
      "start_line": 13,
      "end_line": 15,
      "code": "def get_file_extension(file_path):\n    \"\"\"Get file extension without the dot.\"\"\"\n    return os.path.splitext(file_path)[1][1:].lower()",
      "doc": "Get file extension without the dot.",
      "num_calls_out": 0,
      "num_calls_in": 1,
      "loc": 3,
      "cyclomatic": 1
    },
    {
      "id": "function:get_language_from_extension:worker/parse_repo.py:17",
      "name": "get_language_from_extension",
      "file": "worker/parse_repo.py",
      "start_line": 17,
      "end_line": 31,
      "code": "def get_language_from_extension(extension):\n    \"\"\"Map file extensions to tree-sitter language names.\"\"\"\n    extension_map = {\n        'py': 'python',\n        'js': 'javascript',\n        'ts': 'typescript',\n        'java': 'java',\n        'cpp': 'cpp',\n        'c': 'c',\n        'rs': 'rust',\n        'go': 'go',\n        'html': 'html',\n        'css': 'css',\n    }\n    return extension_map.get(extension)",
      "doc": "Map file extensions to tree-sitter language names.",
      "num_calls_out": 0,
      "num_calls_in": 1,
      "loc": 15,
      "cyclomatic": 1
    },
    {
      "id": "function:extract_docstring_from_source:worker/parse_repo.py:33",
      "name": "extract_docstring_from_source",
      "file": "worker/parse_repo.py",
      "start_line": 33,
      "end_line": 56,
      "code": "def extract_docstring_from_source(source_lines, start_line, end_line):\n    \"\"\"Extract docstring from source code lines for tree-sitter parsed nodes.\"\"\"\n    # Look for docstring in the first few lines after the definition\n    for i in range(start_line, min(start_line + 5, end_line, len(source_lines))):\n        line = source_lines[i].strip()\n        if line.startswith('\"\"\"') or line.startswith(\"'''\"):\n            # Found start of docstring\n            quote_type = '\"\"\"' if line.startswith('\"\"\"') else \"'''\"\n            docstring_lines = []\n            \n            # Check if it's a single-line docstring\n            if line.count(quote_type) >= 2:\n                return line.strip(quote_type).strip()\n            \n            # Multi-line docstring\n            docstring_lines.append(line[3:])  # Remove opening quotes\n            for j in range(i + 1, min(end_line, len(source_lines))):\n                doc_line = source_lines[j]\n                if quote_type in doc_line:\n                    # Found closing quotes\n                    docstring_lines.append(doc_line[:doc_line.find(quote_type)])\n                    return '\\n'.join(docstring_lines).strip()\n                docstring_lines.append(doc_line.rstrip())\n    return \"\"",
      "doc": "Extract docstring from source code lines for tree-sitter parsed nodes.",
      "num_calls_out": 0,
      "num_calls_in": 2,
      "loc": 24,
      "cyclomatic": 7
    },
    {
      "id": "function:parse_file:worker/parse_repo.py:58",
      "name": "parse_file",
      "file": "worker/parse_repo.py",
      "start_line": 58,
      "end_line": 169,
      "code": "def parse_file(file_path):\n    \"\"\"\n    Parse a file to extract functions and classes with metadata.\n    \n    Args:\n        file_path (str): Path to the file to parse\n    \n    Returns:\n        list: List of node dictionaries with keys:\n            - id: Unique identifier for the node\n            - name: Function/class name\n            - file: Relative file path\n            - start_line: Starting line number\n            - end_line: Ending line number\n            - code: Code snippet\n            - doc: Docstring if present\n    \"\"\"\n    if not os.path.exists(file_path):\n        return []\n    extension = get_file_extension(file_path)\n    language = get_language_from_extension(extension)\n    source_code = read_file(file_path)\n    source_lines = source_code.splitlines()\n    nodes = []\n    # Try tree-sitter first\n    if language:\n        try:\n            parser = get_ts_parser(language)\n            tree = parser.parse(bytes(source_code, 'utf8'))\n            def traverse(node):\n                if node.type in ['function_definition', 'function_declaration', 'method_definition']:\n                    name_node = next((c for c in node.children if c.type == 'identifier'), None)\n                    if name_node:\n                        name = source_code[name_node.start_byte:name_node.end_byte]\n                        start_line = node.start_point[0] + 1\n                        end_line = node.end_point[0] + 1\n                        code = '\\n'.join(source_lines[start_line-1:end_line])\n                        doc = extract_docstring_from_source(source_lines, start_line, end_line)\n                        node_id = f\"function:{name}:{os.path.relpath(file_path)}:{start_line}\"\n                        nodes.append({\n                            \"id\": node_id,\n                            \"name\": name,\n                            \"file\": os.path.relpath(file_path),\n                            \"start_line\": start_line,\n                            \"end_line\": end_line,\n                            \"code\": code,\n                            \"doc\": doc\n                        })\n                elif node.type in ['class_definition', 'class_declaration']:\n                    name_node = next((c for c in node.children if c.type == 'identifier'), None)\n                    if name_node:\n                        name = source_code[name_node.start_byte:name_node.end_byte]\n                        start_line = node.start_point[0] + 1\n                        end_line = node.end_point[0] + 1\n                        code = '\\n'.join(source_lines[start_line-1:end_line])\n                        doc = extract_docstring_from_source(source_lines, start_line, end_line)\n                        node_id = f\"class:{name}:{os.path.relpath(file_path)}:{start_line}\"\n                        nodes.append({\n                            \"id\": node_id,\n                            \"name\": name,\n                            \"file\": os.path.relpath(file_path),\n                            \"start_line\": start_line,\n                            \"end_line\": end_line,\n                            \"code\": code,\n                            \"doc\": doc\n                        })\n                for child in node.children:\n                    traverse(child)\n            traverse(tree.root_node)\n            if nodes:\n                return nodes\n        except Exception:\n            pass\n    # Fallback to AST for Python\n    if extension == 'py':\n        try:\n            tree = parse_with_ast(source_code)\n            for node in ast.walk(tree):\n                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                    start_line = node.lineno\n                    end_line = getattr(node, 'end_lineno', start_line)\n                    code = '\\n'.join(source_lines[start_line-1:end_line])\n                    doc = ast.get_docstring(node) or \"\"\n                    node_id = f\"function:{node.name}:{os.path.relpath(file_path)}:{start_line}\"\n                    nodes.append({\n                        \"id\": node_id,\n                        \"name\": node.name,\n                        \"file\": os.path.relpath(file_path),\n                        \"start_line\": start_line,\n                        \"end_line\": end_line,\n                        \"code\": code,\n                        \"doc\": doc\n                    })\n                elif isinstance(node, ast.ClassDef):\n                    start_line = node.lineno\n                    end_line = getattr(node, 'end_lineno', start_line)\n                    code = '\\n'.join(source_lines[start_line-1:end_line])\n                    doc = ast.get_docstring(node) or \"\"\n                    node_id = f\"class:{node.name}:{os.path.relpath(file_path)}:{start_line}\"\n                    nodes.append({\n                        \"id\": node_id,\n                        \"name\": node.name,\n                        \"file\": os.path.relpath(file_path),\n                        \"start_line\": start_line,\n                        \"end_line\": end_line,\n                        \"code\": code,\n                        \"doc\": doc\n                    })\n            return nodes\n        except Exception:\n            return []\n    return []",
      "doc": "Parse a file to extract functions and classes with metadata.\n\nArgs:\n    file_path (str): Path to the file to parse\n\nReturns:\n    list: List of node dictionaries with keys:\n        - id: Unique identifier for the node\n        - name: Function/class name\n        - file: Relative file path\n        - start_line: Starting line number\n        - end_line: Ending line number\n        - code: Code snippet\n        - doc: Docstring if present",
      "num_calls_out": 9,
      "num_calls_in": 1,
      "loc": 112,
      "cyclomatic": 21
    },
    {
      "id": "function:build_nodes:worker/parse_repo.py:171",
      "name": "build_nodes",
      "file": "worker/parse_repo.py",
      "start_line": 171,
      "end_line": 192,
      "code": "def build_nodes(repo_root):\n    \"\"\"\n    Walk through repository and parse all Python files to build node collection.\n    \n    Args:\n        repo_root (str): Root directory of the repository\n    \n    Returns:\n        tuple: (nodes_list, name_to_node_map)\n            - nodes_list: List of all parsed nodes\n            - name_to_node_map: Dict mapping function/class names to list of node IDs\n    \"\"\"\n    nodes = []\n    for root, _, files in os.walk(repo_root):\n        for f in files:\n            if f.endswith('.py'):\n                p = os.path.join(root, f)\n                nodes.extend(parse_file(p))\n    name_map = {}\n    for n in nodes:\n        name_map.setdefault(n['name'], []).append(n['id'])\n    return nodes, name_map",
      "doc": "Walk through repository and parse all Python files to build node collection.\n\nArgs:\n    repo_root (str): Root directory of the repository\n\nReturns:\n    tuple: (nodes_list, name_to_node_map)\n        - nodes_list: List of all parsed nodes\n        - name_to_node_map: Dict mapping function/class names to list of node IDs",
      "num_calls_out": 1,
      "num_calls_in": 1,
      "loc": 22,
      "cyclomatic": 5
    },
    {
      "id": "function:extract_edges:worker/parse_repo.py:194",
      "name": "extract_edges",
      "file": "worker/parse_repo.py",
      "start_line": 194,
      "end_line": 232,
      "code": "def extract_edges(nodes, name_map):\n    \"\"\"\n    Extract edges between nodes by analyzing function calls and imports.\n    \n    Args:\n        nodes (list): List of parsed nodes\n        name_map (dict): Mapping of function/class names to node IDs\n    \n    Returns:\n        list: List of edge dictionaries with from/to/type information\n    \"\"\"\n    edges = []\n    id_by_name = name_map\n    for node in nodes:\n        try:\n            src = node['code']\n            tree = ast.parse(src)\n            for n in ast.walk(tree):\n                if isinstance(n, ast.Call):\n                    if isinstance(n.func, ast.Name):\n                        called = n.func.id\n                        if called in id_by_name:\n                            for target_id in id_by_name[called]:\n                                edges.append({\"from\": node['id'], \"to\": target_id, \"type\": \"call\"})\n                    elif isinstance(n.func, ast.Attribute):\n                        attr = n.func.attr\n                        if attr in id_by_name:\n                            for target_id in id_by_name[attr]:\n                                edges.append({\"from\": node['id'], \"to\": target_id, \"type\": \"call\", \"ambiguous\": True})\n                elif isinstance(n, ast.Import):\n                    for alias in n.names:\n                        edges.append({\"from\": node['file'], \"to\": alias.name, \"type\": \"import\"})\n                elif isinstance(n, ast.ImportFrom):\n                    module = n.module or \"\"\n                    for alias in n.names:\n                        edges.append({\"from\": node['file'], \"to\": f\"{module}.{alias.name}\", \"type\": \"import\"})\n        except Exception:\n            continue\n    return edges",
      "doc": "Extract edges between nodes by analyzing function calls and imports.\n\nArgs:\n    nodes (list): List of parsed nodes\n    name_map (dict): Mapping of function/class names to node IDs\n\nReturns:\n    list: List of edge dictionaries with from/to/type information",
      "num_calls_out": 0,
      "num_calls_in": 1,
      "loc": 39,
      "cyclomatic": 17
    },
    {
      "id": "function:calculate_cyclomatic_complexity:worker/parse_repo.py:234",
      "name": "calculate_cyclomatic_complexity",
      "file": "worker/parse_repo.py",
      "start_line": 234,
      "end_line": 261,
      "code": "def calculate_cyclomatic_complexity(code):\n    \"\"\"\n    Calculate basic cyclomatic complexity heuristic.\n    \n    Args:\n        code (str): Source code to analyze\n    \n    Returns:\n        int: Cyclomatic complexity (number of decision points + 1)\n    \"\"\"\n    try:\n        tree = ast.parse(code)\n        complexity = 1  # Base complexity\n        \n        for node in ast.walk(tree):\n            # Count decision points\n            if isinstance(node, (ast.If, ast.For, ast.While, ast.With, ast.Try, ast.ExceptHandler)):\n                complexity += 1\n            elif isinstance(node, ast.BoolOp):\n                # Count additional conditions in boolean operations\n                complexity += len(node.values) - 1\n            elif isinstance(node, (ast.ListComp, ast.SetComp, ast.DictComp, ast.GeneratorExp)):\n                # Comprehensions add complexity\n                complexity += 1\n        \n        return complexity\n    except Exception:\n        return 1  # Default complexity",
      "doc": "Calculate basic cyclomatic complexity heuristic.\n\nArgs:\n    code (str): Source code to analyze\n\nReturns:\n    int: Cyclomatic complexity (number of decision points + 1)",
      "num_calls_out": 0,
      "num_calls_in": 1,
      "loc": 28,
      "cyclomatic": 7
    },
    {
      "id": "function:annotate_nodes:worker/parse_repo.py:263",
      "name": "annotate_nodes",
      "file": "worker/parse_repo.py",
      "start_line": 263,
      "end_line": 301,
      "code": "def annotate_nodes(nodes, edges):\n    \"\"\"\n    Annotate nodes with additional metadata including call counts and complexity.\n    \n    Args:\n        nodes (list): List of node dictionaries to annotate\n        edges (list): List of edge dictionaries for call counting\n    \n    Returns:\n        None: Modifies nodes in place\n    \"\"\"\n    # Count incoming and outgoing calls\n    incoming = {}\n    outgoing = {}\n    \n    for e in edges:\n        if e.get('type') == 'call':  # Only count call edges, not imports\n            from_id = e['from']\n            to_id = e['to']\n            \n            outgoing.setdefault(from_id, 0)\n            outgoing[from_id] += 1\n            \n            incoming.setdefault(to_id, 0)\n            incoming[to_id] += 1\n    \n    # Annotate each node\n    for n in nodes:\n        node_id = n['id']\n        \n        # Call counts\n        n['num_calls_out'] = int(outgoing.get(node_id, 0))\n        n['num_calls_in'] = int(incoming.get(node_id, 0))\n        \n        # Lines of code\n        n['loc'] = int(n['end_line'] - n['start_line'] + 1)\n        \n        # Cyclomatic complexity\n        n['cyclomatic'] = int(calculate_cyclomatic_complexity(n['code']))",
      "doc": "Annotate nodes with additional metadata including call counts and complexity.\n\nArgs:\n    nodes (list): List of node dictionaries to annotate\n    edges (list): List of edge dictionaries for call counting\n\nReturns:\n    None: Modifies nodes in place",
      "num_calls_out": 1,
      "num_calls_in": 1,
      "loc": 39,
      "cyclomatic": 4
    },
    {
      "id": "function:build_graph:worker/parse_repo.py:303",
      "name": "build_graph",
      "file": "worker/parse_repo.py",
      "start_line": 303,
      "end_line": 334,
      "code": "def build_graph(nodes, edges):\n    \"\"\"\n    Construct a NetworkX DiGraph from nodes and edges.\n    \n    Args:\n        nodes (list): List of node dictionaries\n        edges (list): List of edge dictionaries\n    \n    Returns:\n        nx.DiGraph: NetworkX directed graph with node and edge attributes\n    \"\"\"\n    G = nx.DiGraph()\n    \n    # Add nodes with all their attributes\n    for node in nodes:\n        node_id = node['id']\n        # Create a copy of node data for graph attributes\n        node_attrs = {k: v for k, v in node.items() if k != 'id'}\n        G.add_node(node_id, **node_attrs)\n    \n    # Add edges with their attributes\n    for edge in edges:\n        from_id = edge['from']\n        to_id = edge['to']\n        # Create a copy of edge data for graph attributes\n        edge_attrs = {k: v for k, v in edge.items() if k not in ['from', 'to']}\n        \n        # Only add edge if both nodes exist in the graph\n        if from_id in G.nodes and to_id in G.nodes:\n            G.add_edge(from_id, to_id, **edge_attrs)\n    \n    return G",
      "doc": "Construct a NetworkX DiGraph from nodes and edges.\n\nArgs:\n    nodes (list): List of node dictionaries\n    edges (list): List of edge dictionaries\n\nReturns:\n    nx.DiGraph: NetworkX directed graph with node and edge attributes",
      "num_calls_out": 0,
      "num_calls_in": 1,
      "loc": 32,
      "cyclomatic": 7
    },
    {
      "id": "function:save_graph_json:worker/parse_repo.py:336",
      "name": "save_graph_json",
      "file": "worker/parse_repo.py",
      "start_line": 336,
      "end_line": 369,
      "code": "def save_graph_json(nodes, edges, out_path):\n    \"\"\"\n    Save graph data in JSON format suitable for frontend consumption.\n    \n    Args:\n        nodes (list): List of annotated node dictionaries\n        edges (list): List of edge dictionaries\n        out_path (str): Output file path for JSON\n    \n    Returns:\n        None: Writes JSON file to disk\n    \"\"\"\n    # Prepare the graph data structure\n    graph_data = {\n        \"nodes\": nodes,\n        \"edges\": edges,\n        \"metadata\": {\n            \"node_count\": len(nodes),\n            \"edge_count\": len(edges),\n            \"generated_by\": \"RepoCanvas parser\",\n            \"schema_version\": \"1.0\"\n        }\n    }\n    \n    # Ensure output directory exists\n    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n    \n    # Write JSON file\n    with open(out_path, 'w', encoding='utf-8') as f:\n        json.dump(graph_data, f, indent=2, ensure_ascii=False)\n    \n    print(f\"Graph saved to {out_path}\")\n    print(f\"  - Nodes: {len(nodes)}\")\n    print(f\"  - Edges: {len(edges)}\")",
      "doc": "Save graph data in JSON format suitable for frontend consumption.\n\nArgs:\n    nodes (list): List of annotated node dictionaries\n    edges (list): List of edge dictionaries\n    out_path (str): Output file path for JSON\n\nReturns:\n    None: Writes JSON file to disk",
      "num_calls_out": 0,
      "num_calls_in": 1,
      "loc": 34,
      "cyclomatic": 2
    },
    {
      "id": "function:build_repository_graph:worker/parse_repo.py:371",
      "name": "build_repository_graph",
      "file": "worker/parse_repo.py",
      "start_line": 371,
      "end_line": 406,
      "code": "def build_repository_graph(repo_root, output_path=None):\n    \"\"\"\n    Complete pipeline to build and save repository graph.\n    \n    Args:\n        repo_root (str): Root directory of repository to analyze\n        output_path (str, optional): Path to save graph.json (default: repo_root/graph.json)\n    \n    Returns:\n        tuple: (nodes, edges, graph) - The complete graph data\n    \"\"\"\n    if output_path is None:\n        output_path = os.path.join(repo_root, \"graph.json\")\n    \n    print(f\"Analyzing repository: {repo_root}\")\n    \n    # Step 1: Parse all files and build nodes\n    nodes, name_map = build_nodes(repo_root)\n    print(f\"Found {len(nodes)} nodes\")\n    \n    # Step 2: Extract edges between nodes\n    edges = extract_edges(nodes, name_map)\n    print(f\"Found {len(edges)} edges\")\n    \n    # Step 3: Annotate nodes with metadata\n    annotate_nodes(nodes, edges)\n    print(\"Annotated nodes with metadata\")\n    \n    # Step 4: Build NetworkX graph\n    graph = build_graph(nodes, edges)\n    print(f\"Built NetworkX graph: {len(graph.nodes)} nodes, {len(graph.edges)} edges\")\n    \n    # Step 5: Save to JSON\n    save_graph_json(nodes, edges, output_path)\n    \n    return nodes, edges, graph",
      "doc": "Complete pipeline to build and save repository graph.\n\nArgs:\n    repo_root (str): Root directory of repository to analyze\n    output_path (str, optional): Path to save graph.json (default: repo_root/graph.json)\n\nReturns:\n    tuple: (nodes, edges, graph) - The complete graph data",
      "num_calls_out": 7,
      "num_calls_in": 0,
      "loc": 36,
      "cyclomatic": 2
    },
    {
      "id": "function:traverse:worker/parse_repo.py:87",
      "name": "traverse",
      "file": "worker/parse_repo.py",
      "start_line": 87,
      "end_line": 125,
      "code": "            def traverse(node):\n                if node.type in ['function_definition', 'function_declaration', 'method_definition']:\n                    name_node = next((c for c in node.children if c.type == 'identifier'), None)\n                    if name_node:\n                        name = source_code[name_node.start_byte:name_node.end_byte]\n                        start_line = node.start_point[0] + 1\n                        end_line = node.end_point[0] + 1\n                        code = '\\n'.join(source_lines[start_line-1:end_line])\n                        doc = extract_docstring_from_source(source_lines, start_line, end_line)\n                        node_id = f\"function:{name}:{os.path.relpath(file_path)}:{start_line}\"\n                        nodes.append({\n                            \"id\": node_id,\n                            \"name\": name,\n                            \"file\": os.path.relpath(file_path),\n                            \"start_line\": start_line,\n                            \"end_line\": end_line,\n                            \"code\": code,\n                            \"doc\": doc\n                        })\n                elif node.type in ['class_definition', 'class_declaration']:\n                    name_node = next((c for c in node.children if c.type == 'identifier'), None)\n                    if name_node:\n                        name = source_code[name_node.start_byte:name_node.end_byte]\n                        start_line = node.start_point[0] + 1\n                        end_line = node.end_point[0] + 1\n                        code = '\\n'.join(source_lines[start_line-1:end_line])\n                        doc = extract_docstring_from_source(source_lines, start_line, end_line)\n                        node_id = f\"class:{name}:{os.path.relpath(file_path)}:{start_line}\"\n                        nodes.append({\n                            \"id\": node_id,\n                            \"name\": name,\n                            \"file\": os.path.relpath(file_path),\n                            \"start_line\": start_line,\n                            \"end_line\": end_line,\n                            \"code\": code,\n                            \"doc\": doc\n                        })\n                for child in node.children:\n                    traverse(child)",
      "doc": "",
      "num_calls_out": 0,
      "num_calls_in": 2,
      "loc": 39,
      "cyclomatic": 1
    },
    {
      "id": "function:demo_clone_repo:worker/demo_example.py:25",
      "name": "demo_clone_repo",
      "file": "worker/demo_example.py",
      "start_line": 25,
      "end_line": 52,
      "code": "def demo_clone_repo():\n    \"\"\"Demonstrate repository cloning functionality.\"\"\"\n    print(\"=\" * 50)\n    print(\"DEMO: Repository Cloning\")\n    print(\"=\" * 50)\n    \n    try:\n        # Use a temporary directory for the demo\n        with tempfile.TemporaryDirectory() as temp_dir:\n            repo_path = os.path.join(temp_dir, \"demo_repo\")\n            \n            print(f\"Cloning repository to: {repo_path}\")\n            result = clone_repo(\n                \"https://github.com/octocat/Hello-World.git\",\n                repo_path,\n                branch=\"master\",  # This repo uses 'master' branch\n                depth=1\n            )\n            \n            print(f\"✓ Successfully cloned to: {result}\")\n            print(f\"✓ Directory exists: {os.path.exists(result)}\")\n            \n            # List repository contents\n            files = os.listdir(result)\n            print(f\"✓ Repository contents: {files}\")\n            \n    except Exception as e:\n        print(f\"✗ Error during repository cloning: {e}\")",
      "doc": "Demonstrate repository cloning functionality.",
      "num_calls_out": 1,
      "num_calls_in": 0,
      "loc": 28,
      "cyclomatic": 4
    },
    {
      "id": "function:demo_ast_parsing:worker/demo_example.py:55",
      "name": "demo_ast_parsing",
      "file": "worker/demo_example.py",
      "start_line": 55,
      "end_line": 101,
      "code": "def demo_ast_parsing():\n    \"\"\"Demonstrate Python AST parsing functionality.\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"DEMO: Python AST Parsing\")\n    print(\"=\" * 50)\n    \n    # Test with valid Python code\n    valid_code = '''\ndef fibonacci(n):\n    \"\"\"Calculate the nth Fibonacci number.\"\"\"\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n\n# Calculate Fibonacci of 10\nresult = fibonacci(10)\nprint(f\"Fibonacci(10) = {result}\")\n'''\n    \n    try:\n        print(\"Parsing valid Python code...\")\n        ast_tree = parse_with_ast(valid_code)\n        print(f\"✓ AST parsing successful!\")\n        print(f\"✓ Root node type: {type(ast_tree).__name__}\")\n        print(f\"✓ Number of top-level statements: {len(ast_tree.body)}\")\n        \n        # Print the first statement details\n        if ast_tree.body:\n            first_stmt = ast_tree.body[0]\n            print(f\"✓ First statement type: {type(first_stmt).__name__}\")\n            if hasattr(first_stmt, 'name'):\n                print(f\"✓ Function name: {first_stmt.name}\")\n                \n    except Exception as e:\n        print(f\"✗ Error parsing valid code: {e}\")\n    \n    # Test with invalid Python code\n    invalid_code = \"def broken_function(\\n    # missing closing parenthesis and colon\"\n    \n    try:\n        print(\"\\nTesting with invalid Python code...\")\n        parse_with_ast(invalid_code)\n        print(\"✗ Unexpected: parsing succeeded for invalid code\")\n    except SyntaxError as e:\n        print(f\"✓ Expected SyntaxError caught: {e}\")\n    except Exception as e:\n        print(f\"✗ Unexpected error: {e}\")",
      "doc": "Demonstrate Python AST parsing functionality.",
      "num_calls_out": 2,
      "num_calls_in": 0,
      "loc": 47,
      "cyclomatic": 8
    },
    {
      "id": "function:demo_tree_sitter:worker/demo_example.py:104",
      "name": "demo_tree_sitter",
      "file": "worker/demo_example.py",
      "start_line": 104,
      "end_line": 126,
      "code": "def demo_tree_sitter():\n    \"\"\"Demonstrate tree-sitter functionality (will show expected error without library).\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"DEMO: Tree-sitter Parsing\")\n    print(\"=\" * 50)\n    \n    try:\n        print(\"Attempting to get Python parser...\")\n        parser = get_ts_parser('python')\n        print(\"✓ Tree-sitter parser created successfully!\")\n        \n        # If we reach here, the library exists and we can test parsing\n        test_code = \"def hello(): return 'world'\"\n        tree = parser.parse(bytes(test_code, 'utf8'))\n        print(f\"✓ Parsing successful! Root node: {tree.root_node}\")\n        \n    except FileNotFoundError as e:\n        print(f\"⚠ Expected: Tree-sitter library not found\")\n        print(f\"  Message: {e}\")\n        print(\"  To build the library, see worker/parser/build/README.md\")\n        \n    except Exception as e:\n        print(f\"✗ Unexpected error: {e}\")",
      "doc": "Demonstrate tree-sitter functionality (will show expected error without library).",
      "num_calls_out": 1,
      "num_calls_in": 0,
      "loc": 23,
      "cyclomatic": 4
    },
    {
      "id": "function:demo_build_instructions:worker/demo_example.py:129",
      "name": "demo_build_instructions",
      "file": "worker/demo_example.py",
      "start_line": 129,
      "end_line": 145,
      "code": "def demo_build_instructions():\n    \"\"\"Show instructions for building tree-sitter library.\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"DEMO: Building Tree-sitter Library\")\n    print(\"=\" * 50)\n    \n    print(\"To build a tree-sitter library with language support:\")\n    print(\"\\n1. Clone language repositories:\")\n    print(\"   git clone https://github.com/tree-sitter/tree-sitter-python\")\n    print(\"   git clone https://github.com/tree-sitter/tree-sitter-javascript\")\n    print(\"\\n2. Build the library in Python:\")\n    print(\"   from parser.ts_parser import build_tree_sitter_lib\")\n    print(\"   langs_dirs = ['path/to/tree-sitter-python', 'path/to/tree-sitter-javascript']\")\n    print(\"   build_tree_sitter_lib(langs_dirs)\")\n    print(\"\\n3. Use the parser:\")\n    print(\"   from parser.ts_parser import get_ts_parser\")\n    print(\"   parser = get_ts_parser('python')\")",
      "doc": "Show instructions for building tree-sitter library.",
      "num_calls_out": 0,
      "num_calls_in": 0,
      "loc": 17,
      "cyclomatic": 1
    },
    {
      "id": "function:build_graph:worker/graph/graph_loader.py:5",
      "name": "build_graph",
      "file": "worker/graph/graph_loader.py",
      "start_line": 5,
      "end_line": 12,
      "code": "def build_graph(nodes, edges):\n    G = nx.DiGraph()\n    for n in nodes:\n        G.add_node(n['id'], **n)\n    for e in edges:\n        src, tgt = e['from'], e['to']\n        G.add_edge(src, tgt, **{k:v for k,v in e.items() if k not in ['from','to']})\n    return G",
      "doc": "",
      "num_calls_out": 0,
      "num_calls_in": 1,
      "loc": 8,
      "cyclomatic": 4
    },
    {
      "id": "function:save_graph_json:worker/graph/graph_loader.py:14",
      "name": "save_graph_json",
      "file": "worker/graph/graph_loader.py",
      "start_line": 14,
      "end_line": 16,
      "code": "def save_graph_json(nodes, edges, out_path):\n    with open(out_path, 'w', encoding='utf-8') as f:\n        json.dump({\"nodes\": nodes, \"edges\": edges}, f, indent=2)",
      "doc": "",
      "num_calls_out": 0,
      "num_calls_in": 1,
      "loc": 3,
      "cyclomatic": 2
    },
    {
      "id": "function:build_tree_sitter_lib:worker/parser/ts_parser.py:8",
      "name": "build_tree_sitter_lib",
      "file": "worker/parser/ts_parser.py",
      "start_line": 8,
      "end_line": 21,
      "code": "def build_tree_sitter_lib(langs_dirs, output=BUILD_LIB):\n    \"\"\"\n    Build a tree-sitter language library from source directories.\n    \n    Args:\n        langs_dirs (list): List of paths to tree-sitter language source directories\n        output (str): Output path for the compiled library (default: BUILD_LIB)\n    \n    Returns:\n        str: Path to the built library\n    \"\"\"\n    # Example: langs_dirs = ['../../vendor/tree-sitter-python', '../../vendor/tree-sitter-javascript']\n    Language.build_library(output, langs_dirs)\n    return output",
      "doc": "Build a tree-sitter language library from source directories.\n\nArgs:\n    langs_dirs (list): List of paths to tree-sitter language source directories\n    output (str): Output path for the compiled library (default: BUILD_LIB)\n\nReturns:\n    str: Path to the built library",
      "num_calls_out": 0,
      "num_calls_in": 0,
      "loc": 14,
      "cyclomatic": 1
    },
    {
      "id": "function:get_ts_parser:worker/parser/ts_parser.py:23",
      "name": "get_ts_parser",
      "file": "worker/parser/ts_parser.py",
      "start_line": 23,
      "end_line": 57,
      "code": "def get_ts_parser(language_name):\n    \"\"\"\n    Create a tree-sitter Parser for the specified language.\n    \n    Args:\n        language_name (str): Name of the language (e.g., 'python', 'javascript', 'typescript')\n    \n    Returns:\n        Parser: Configured tree-sitter Parser instance\n    \n    Raises:\n        FileNotFoundError: If the shared library is not found\n        Exception: If the language is not available in the library\n    \"\"\"\n    if not os.path.exists(BUILD_LIB):\n        raise FileNotFoundError(\n            f\"Tree-sitter shared library not found at '{BUILD_LIB}'. \"\n            f\"Please build the library first using build_tree_sitter_lib() or ensure the file exists. \"\n            f\"You may need to compile tree-sitter languages and place the shared library at this location.\"\n        )\n    \n    try:\n        LANG = Language(BUILD_LIB, language_name)\n    except Exception as e:\n        available_languages = _get_available_languages()\n        raise Exception(\n            f\"Failed to load language '{language_name}' from '{BUILD_LIB}'. \"\n            f\"Error: {e}. \"\n            f\"Available languages in the library: {available_languages}. \"\n            f\"Please ensure '{language_name}' is compiled into the shared library.\"\n        )\n    \n    parser = Parser()\n    parser.set_language(LANG)\n    return parser",
      "doc": "Create a tree-sitter Parser for the specified language.\n\nArgs:\n    language_name (str): Name of the language (e.g., 'python', 'javascript', 'typescript')\n\nReturns:\n    Parser: Configured tree-sitter Parser instance\n\nRaises:\n    FileNotFoundError: If the shared library is not found\n    Exception: If the language is not available in the library",
      "num_calls_out": 1,
      "num_calls_in": 2,
      "loc": 35,
      "cyclomatic": 4
    },
    {
      "id": "function:_get_available_languages:worker/parser/ts_parser.py:59",
      "name": "_get_available_languages",
      "file": "worker/parser/ts_parser.py",
      "start_line": 59,
      "end_line": 81,
      "code": "def _get_available_languages():\n    \"\"\"\n    Attempt to get a list of available languages in the shared library.\n    This is a helper function for error reporting.\n    \n    Returns:\n        list: List of language names if available, otherwise a helpful message\n    \"\"\"\n    if not os.path.exists(BUILD_LIB):\n        return [\"Library not found\"]\n    \n    # Common tree-sitter language names\n    common_languages = ['python', 'javascript', 'typescript', 'java', 'cpp', 'c', 'rust', 'go', 'html', 'css']\n    available = []\n    \n    for lang in common_languages:\n        try:\n            Language(BUILD_LIB, lang)\n            available.append(lang)\n        except:\n            continue\n    \n    return available if available else [\"Unable to determine - check library compilation\"]",
      "doc": "Attempt to get a list of available languages in the shared library.\nThis is a helper function for error reporting.\n\nReturns:\n    list: List of language names if available, otherwise a helpful message",
      "num_calls_out": 0,
      "num_calls_in": 1,
      "loc": 23,
      "cyclomatic": 5
    },
    {
      "id": "function:parse_with_ast:worker/parser/ts_parser.py:83",
      "name": "parse_with_ast",
      "file": "worker/parser/ts_parser.py",
      "start_line": 83,
      "end_line": 107,
      "code": "def parse_with_ast(source_code):\n    \"\"\"\n    Parse Python source code using the built-in ast module as a fallback.\n    \n    Args:\n        source_code (str): Python source code to parse\n    \n    Returns:\n        ast.AST: Abstract syntax tree node\n    \n    Raises:\n        SyntaxError: If the source code has syntax errors\n        Exception: For other parsing errors\n    \"\"\"\n    if not isinstance(source_code, str):\n        raise TypeError(f\"Expected string input, got {type(source_code).__name__}\")\n    \n    try:\n        return ast.parse(source_code)\n    except SyntaxError as e:\n        raise SyntaxError(\n            f\"Python syntax error in source code at line {e.lineno}, column {e.offset}: {e.msg}\"\n        )\n    except Exception as e:\n        raise Exception(f\"Failed to parse Python source code with ast module: {e}\")",
      "doc": "Parse Python source code using the built-in ast module as a fallback.\n\nArgs:\n    source_code (str): Python source code to parse\n\nReturns:\n    ast.AST: Abstract syntax tree node\n\nRaises:\n    SyntaxError: If the source code has syntax errors\n    Exception: For other parsing errors",
      "num_calls_out": 0,
      "num_calls_in": 3,
      "loc": 25,
      "cyclomatic": 5
    },
    {
      "id": "function:clone_repo:worker/parser/utils.py:8",
      "name": "clone_repo",
      "file": "worker/parser/utils.py",
      "start_line": 8,
      "end_line": 68,
      "code": "def clone_repo(repo_url: str, dest_dir: str, branch: str = \"main\", depth: int = 1):\n    \"\"\"\n    Clone a git repository using GitPython with subprocess fallback.\n    \n    Args:\n        repo_url (str): The URL of the repository to clone\n        dest_dir (str): Destination directory for the cloned repository\n        branch (str): Branch to clone (default: 'main')\n        depth (int): Depth for shallow clone (default: 1)\n    \n    Returns:\n        str: Path to the cloned repository\n    \n    Raises:\n        Exception: If both GitPython and subprocess git commands fail\n    \"\"\"\n    # Remove destination directory if it exists\n    if os.path.exists(dest_dir):\n        try:\n            shutil.rmtree(dest_dir)\n        except OSError as e:\n            raise Exception(f\"Failed to remove existing directory '{dest_dir}': {e}\")\n    \n    # Create destination directory\n    try:\n        os.makedirs(dest_dir, exist_ok=True)\n    except OSError as e:\n        raise Exception(f\"Failed to create destination directory '{dest_dir}': {e}\")\n    \n    # Try GitPython first\n    try:\n        Repo.clone_from(repo_url, dest_dir, branch=branch, depth=depth)\n        return dest_dir\n    except (GitCommandError, InvalidGitRepositoryError) as e:\n        print(f\"GitPython failed: {e}. Falling back to subprocess git command...\")\n    except Exception as e:\n        print(f\"GitPython failed with unexpected error: {e}. Falling back to subprocess git command...\")\n    \n    # Fallback to subprocess git if GitPython fails\n    try:\n        subprocess.check_call(\n            [\"git\", \"clone\", \"--depth\", str(depth), \"-b\", branch, repo_url, dest_dir],\n            stderr=subprocess.STDOUT\n        )\n        return dest_dir\n    except subprocess.CalledProcessError as e:\n        # Clean up partial clone on failure\n        if os.path.exists(dest_dir):\n            shutil.rmtree(dest_dir)\n        raise Exception(\n            f\"Failed to clone repository '{repo_url}' to '{dest_dir}' on branch '{branch}'. \"\n            f\"Git command failed with exit code {e.returncode}. \"\n            f\"Please check if the repository URL is valid and the branch exists.\"\n        )\n    except FileNotFoundError:\n        # Clean up on failure\n        if os.path.exists(dest_dir):\n            shutil.rmtree(dest_dir)\n        raise Exception(\n            \"Git command not found. Please ensure Git is installed and available in your PATH.\"\n        )",
      "doc": "Clone a git repository using GitPython with subprocess fallback.\n\nArgs:\n    repo_url (str): The URL of the repository to clone\n    dest_dir (str): Destination directory for the cloned repository\n    branch (str): Branch to clone (default: 'main')\n    depth (int): Depth for shallow clone (default: 1)\n\nReturns:\n    str: Path to the cloned repository\n\nRaises:\n    Exception: If both GitPython and subprocess git commands fail",
      "num_calls_out": 0,
      "num_calls_in": 1,
      "loc": 61,
      "cyclomatic": 14
    }
  ],
  "edges": [
    {
      "from": "function:parse_file:worker/parse_repo.py:58",
      "to": "function:get_file_extension:worker/parse_repo.py:13",
      "type": "call"
    },
    {
      "from": "function:parse_file:worker/parse_repo.py:58",
      "to": "function:get_language_from_extension:worker/parse_repo.py:17",
      "type": "call"
    },
    {
      "from": "function:parse_file:worker/parse_repo.py:58",
      "to": "function:read_file:worker/parse_repo.py:8",
      "type": "call"
    },
    {
      "from": "function:parse_file:worker/parse_repo.py:58",
      "to": "function:get_ts_parser:worker/parser/ts_parser.py:23",
      "type": "call"
    },
    {
      "from": "function:parse_file:worker/parse_repo.py:58",
      "to": "function:traverse:worker/parse_repo.py:87",
      "type": "call"
    },
    {
      "from": "function:parse_file:worker/parse_repo.py:58",
      "to": "function:parse_with_ast:worker/parser/ts_parser.py:83",
      "type": "call"
    },
    {
      "from": "function:parse_file:worker/parse_repo.py:58",
      "to": "function:traverse:worker/parse_repo.py:87",
      "type": "call"
    },
    {
      "from": "function:parse_file:worker/parse_repo.py:58",
      "to": "function:extract_docstring_from_source:worker/parse_repo.py:33",
      "type": "call"
    },
    {
      "from": "function:parse_file:worker/parse_repo.py:58",
      "to": "function:extract_docstring_from_source:worker/parse_repo.py:33",
      "type": "call"
    },
    {
      "from": "function:build_nodes:worker/parse_repo.py:171",
      "to": "function:parse_file:worker/parse_repo.py:58",
      "type": "call"
    },
    {
      "from": "function:annotate_nodes:worker/parse_repo.py:263",
      "to": "function:calculate_cyclomatic_complexity:worker/parse_repo.py:234",
      "type": "call"
    },
    {
      "from": "function:build_repository_graph:worker/parse_repo.py:371",
      "to": "function:build_nodes:worker/parse_repo.py:171",
      "type": "call"
    },
    {
      "from": "function:build_repository_graph:worker/parse_repo.py:371",
      "to": "function:extract_edges:worker/parse_repo.py:194",
      "type": "call"
    },
    {
      "from": "function:build_repository_graph:worker/parse_repo.py:371",
      "to": "function:annotate_nodes:worker/parse_repo.py:263",
      "type": "call"
    },
    {
      "from": "function:build_repository_graph:worker/parse_repo.py:371",
      "to": "function:build_graph:worker/parse_repo.py:303",
      "type": "call"
    },
    {
      "from": "function:build_repository_graph:worker/parse_repo.py:371",
      "to": "function:build_graph:worker/graph/graph_loader.py:5",
      "type": "call"
    },
    {
      "from": "function:build_repository_graph:worker/parse_repo.py:371",
      "to": "function:save_graph_json:worker/parse_repo.py:336",
      "type": "call"
    },
    {
      "from": "function:build_repository_graph:worker/parse_repo.py:371",
      "to": "function:save_graph_json:worker/graph/graph_loader.py:14",
      "type": "call"
    },
    {
      "from": "function:demo_clone_repo:worker/demo_example.py:25",
      "to": "function:clone_repo:worker/parser/utils.py:8",
      "type": "call"
    },
    {
      "from": "function:demo_ast_parsing:worker/demo_example.py:55",
      "to": "function:parse_with_ast:worker/parser/ts_parser.py:83",
      "type": "call"
    },
    {
      "from": "function:demo_ast_parsing:worker/demo_example.py:55",
      "to": "function:parse_with_ast:worker/parser/ts_parser.py:83",
      "type": "call"
    },
    {
      "from": "function:demo_tree_sitter:worker/demo_example.py:104",
      "to": "function:get_ts_parser:worker/parser/ts_parser.py:23",
      "type": "call"
    },
    {
      "from": "function:get_ts_parser:worker/parser/ts_parser.py:23",
      "to": "function:_get_available_languages:worker/parser/ts_parser.py:59",
      "type": "call"
    }
  ],
  "metadata": {
    "node_count": 24,
    "edge_count": 23,
    "generated_by": "RepoCanvas parser",
    "schema_version": "1.0"
  }
}